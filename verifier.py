#!/usr/bin/env python3
"""
é¦™æ¸¯æ”¶æ“š OCR æ•¸æ“šé›†å¿«é€Ÿé©—è­‰å·¥å…·
è¼•é‡ç´šç¶²é ç•Œé¢,å¿«é€Ÿé©—è­‰ EasyOCR çš„è­˜åˆ¥çµæœ
"""


import json
import base64
import shutil
import logging
from pathlib import Path
from flask import Flask, render_template, request, jsonify, abort
import cv2
from typing import List, Dict, Optional, Tuple

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class QuickVerifier:
    """è¼•é‡ç´šé©—è­‰å·¥å…·"""

    def __init__(self, processed_dir: str = "./processed", input_dir: str = "./input"):
        """
        åˆå§‹åŒ–é©—è­‰å™¨

        Args:
            processed_dir: è™•ç†çµæœç›®éŒ„è·¯å¾‘
            input_dir: è¼¸å…¥åœ–ç‰‡ç›®éŒ„è·¯å¾‘

        Raises:
            FileNotFoundError: æ¨™è¨»æ–‡ä»¶ä¸å­˜åœ¨
            json.JSONDecodeError: æ¨™è¨»æ–‡ä»¶æ ¼å¼éŒ¯èª¤
        """
        self.processed_dir = Path(processed_dir).resolve()
        self.input_dir = Path(input_dir).resolve()
        self.crops_dir = self.processed_dir / "crops"
        self.annotations_file = self.processed_dir / "annotations.json"
        self.deleted_dir = self.processed_dir / "deleted"

        # å‰µå»ºæ‰€æœ‰å¿…è¦çš„ç›®éŒ„
        self.processed_dir.mkdir(parents=True, exist_ok=True)
        self.deleted_dir.mkdir(parents=True, exist_ok=True)
        self.input_dir.mkdir(parents=True, exist_ok=True)
        self.crops_dir.mkdir(parents=True, exist_ok=True)

        # é©—è­‰æ–‡ä»¶å­˜åœ¨
        if not self.annotations_file.exists():
            logger.warning(f"æ¨™è¨»æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°‡å‰µå»ºæ–°æ–‡ä»¶: {self.annotations_file}")
            self.annotations = {}
            self.save_annotations()
        else:
            # è¼‰å…¥æ¨™è¨»
            try:
                with open(self.annotations_file, 'r', encoding='utf-8') as f:
                    self.annotations = json.load(f)
                logger.info(f"æˆåŠŸè¼‰å…¥ {len(self.annotations)} å€‹æ¨™è¨»")
            except json.JSONDecodeError as e:
                logger.error(f"æ¨™è¨»æ–‡ä»¶æ ¼å¼éŒ¯èª¤: {e}")
                raise
            except Exception as e:
                logger.error(f"è¼‰å…¥æ¨™è¨»å¤±æ•—: {e}")
                raise

        # çµ±è¨ˆ
        self.total_regions = sum(
            len(anno.get('ocr_results', []))
            for anno in self.annotations.values()
        )

        self.verified_regions = 0
        self.corrected_regions = 0

        # è‡ªå‹•æª¢æ¸¬ä¸¦è™•ç† input ç›®éŒ„ä¸­çš„æ–°åœ–ç‰‡
        self.process_input_folder()

    def process_input_folder(self):
        """è‡ªå‹•è™•ç† input ç›®éŒ„ä¸­çš„æ–°åœ–ç‰‡"""
        try:
            # æª¢æŸ¥ input ç›®éŒ„ä¸­çš„åœ–ç‰‡
            image_files = list(self.input_dir.glob('*.jpg')) + \
                list(self.input_dir.glob('*.jpeg')) + \
                list(self.input_dir.glob('*.png'))

            if not image_files:
                logger.info("input ç›®éŒ„ä¸­æ²’æœ‰æ–°åœ–ç‰‡")
                return

            # éæ¿¾å‡ºæœªè™•ç†çš„åœ–ç‰‡
            new_images = [
                img for img in image_files if img.name not in self.annotations]

            if not new_images:
                logger.info(f"input ç›®éŒ„ä¸­çš„ {len(image_files)} å¼µåœ–ç‰‡éƒ½å·²è™•ç†")
                return

            logger.info(f"ç™¼ç¾ {len(new_images)} å¼µæ–°åœ–ç‰‡ï¼Œé–‹å§‹è‡ªå‹•è™•ç†...")

            # å°å…¥ä¸¦ä½¿ç”¨ ReceiptDatasetCreator è™•ç†æ–°åœ–ç‰‡
            import sys
            sys.path.insert(0, str(Path(__file__).parent))
            from create_receipt_dataset import ReceiptDatasetCreator

            creator = ReceiptDatasetCreator()

            for img_path in new_images:
                try:
                    logger.info(f"è™•ç†: {img_path.name}")
                    annotation = creator.ocr_image(img_path)
                    creator.annotations[img_path.name] = annotation
                    self.annotations[img_path.name] = annotation
                    logger.info(
                        f"âœ“ {img_path.name}: ç™¼ç¾ {len(annotation.get('ocr_results', []))} å€‹æ–‡å­—å€åŸŸ")
                except Exception as e:
                    logger.error(f"è™•ç† {img_path.name} å¤±æ•—: {e}")

            # ä¿å­˜æ›´æ–°çš„æ¨™è¨»
            creator.save_annotations()
            self.save_annotations()

            # æ›´æ–°çµ±è¨ˆ
            self.total_regions = sum(
                len(anno.get('ocr_results', []))
                for anno in self.annotations.values()
            )

            logger.info(f"âœ… æˆåŠŸè™•ç† {len(new_images)} å¼µæ–°åœ–ç‰‡")

        except Exception as e:
            logger.error(f"è‡ªå‹•è™•ç† input ç›®éŒ„å¤±æ•—: {e}")

    def save_annotations(self):
        """ä¿å­˜æ¨™è¨»åˆ°æ–‡ä»¶"""
        try:
            self.processed_dir.mkdir(parents=True, exist_ok=True)
            with open(self.annotations_file, 'w', encoding='utf-8') as f:
                json.dump(self.annotations, f, ensure_ascii=False, indent=2)
            logger.info(f"ä¿å­˜æ¨™è¨»: {self.annotations_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜æ¨™è¨»å¤±æ•—: {e}")

    def get_verification_data(self) -> List[Dict]:
        """
        æº–å‚™é©—è­‰æ•¸æ“š

        è¿”å›æ ¼å¼:
        [
            {
                'image_name': 'receipt001.jpg',
                'region_idx': 0,
                'cropped_image': 'base64...',
                'text': 'SUPERNORMAL',
                'confidence': 0.95,
                'verified': False
            },
            ...
        ]

        Returns:
            é©—è­‰é …ç›®åˆ—è¡¨
        """
        verification_items = []

        for image_name, anno in self.annotations.items():
            for idx, ocr_result in enumerate(anno.get('ocr_results', [])):
                try:
                    text = ocr_result['text']
                    confidence = ocr_result['confidence']

                    # ä½¿ç”¨å·²ä¿å­˜çš„è£åˆ‡åœ–ç‰‡
                    crop_filename = ocr_result.get('crop_filename')
                    if not crop_filename:
                        logger.warning(f"ç¼ºå°‘ crop_filename: {image_name}_{idx}")
                        continue

                    crop_path = self.crops_dir / crop_filename
                    if not crop_path.exists():
                        logger.warning(f"è£åˆ‡åœ–ç‰‡ä¸å­˜åœ¨: {crop_path}")
                        continue

                    # è®€å–è£åˆ‡åœ–ç‰‡
                    cropped = cv2.imread(str(crop_path))
                    if cropped is None:
                        logger.error(f"ç„¡æ³•è®€å–è£åˆ‡åœ–ç‰‡: {crop_path}")
                        continue

                    if cropped.size == 0:
                        logger.warning(f"ç©ºç™½è£å‰ªå€åŸŸ: {image_name}_{idx}")
                        continue

                    # è½‰ç‚º base64
                    _, buffer = cv2.imencode('.jpg', cropped)
                    img_base64 = base64.b64encode(buffer).decode('utf-8')

                    verification_items.append({
                        'id': f"{image_name}_{idx}",
                        'image_name': image_name,
                        'region_idx': idx,
                        'cropped_image': img_base64,
                        'text': text,
                        'confidence': confidence,
                        'verified': ocr_result.get('verified', False),
                        'corrected_text': ocr_result.get('corrected_text', None)
                    })
                except Exception as e:
                    logger.error(f"è™•ç†å€åŸŸå¤±æ•— {image_name}_{idx}: {e}")
                    continue

        logger.info(f"æº–å‚™äº† {len(verification_items)} å€‹é©—è­‰é …ç›®")
        return verification_items

    def save_verification(self, updates: List[Dict]) -> bool:
        """
        ä¿å­˜é©—è­‰çµæœ

        Args:
            updates: æ›´æ–°åˆ—è¡¨ï¼Œæ¯é …åŒ…å« image_name, region_idx, verified, corrected_text

        Returns:
            æ˜¯å¦æˆåŠŸä¿å­˜
        """
        try:
            for update in updates:
                # é©—è­‰è¼¸å…¥
                if not isinstance(update, dict):
                    logger.error(f"ç„¡æ•ˆçš„æ›´æ–°æ ¼å¼: {update}")
                    continue

                image_name = update.get('image_name')
                region_idx = update.get('region_idx')

                if not image_name or region_idx is None:
                    logger.error(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {update}")
                    continue

                if image_name in self.annotations:
                    ocr_results = self.annotations[image_name]['ocr_results']
                    if region_idx < len(ocr_results):
                        ocr_results[region_idx]['verified'] = update.get(
                            'verified', False)

                        corrected_text = update.get('corrected_text')
                        if corrected_text:
                            # æ¸…ç†æ–‡å­—ï¼Œé˜²æ­¢ CSV æ³¨å…¥
                            corrected_text = corrected_text.strip()
                            corrected_text = corrected_text.replace(
                                '\n', ' ').replace('\r', '')

                            ocr_results[region_idx]['corrected_text'] = corrected_text
                            ocr_results[region_idx]['text'] = corrected_text
                            logger.info(f"ä¿®æ­£æ–‡å­—: {image_name}_{region_idx}")

            # å‚™ä»½åŸæ–‡ä»¶
            backup_file = self.annotations_file.with_suffix('.json.bak')
            shutil.copy2(self.annotations_file, backup_file)
            logger.info(f"å‚™ä»½æ¨™è¨»æ–‡ä»¶: {backup_file}")

            # ä¿å­˜
            with open(self.annotations_file, 'w', encoding='utf-8') as f:
                json.dump(self.annotations, f, ensure_ascii=False, indent=2)

            logger.info(f"æˆåŠŸä¿å­˜ {len(updates)} å€‹æ›´æ–°")
            return True

        except Exception as e:
            logger.error(f"ä¿å­˜é©—è­‰å¤±æ•—: {e}")
            # æ¢å¾©å‚™ä»½
            backup_file = self.annotations_file.with_suffix('.json.bak')
            if backup_file.exists():
                shutil.copy2(backup_file, self.annotations_file)
                logger.info("å·²å¾å‚™ä»½æ¢å¾©")
            return False

    def delete_regions(self, delete_items: List[Dict]) -> Tuple[bool, int]:
        """
        åˆªé™¤æŒ‡å®šçš„æ–‡å­—å€åŸŸ

        Args:
            delete_items: è¦åˆªé™¤çš„é …ç›®åˆ—è¡¨ï¼Œæ¯é …åŒ…å« image_name, region_idx

        Returns:
            (æ˜¯å¦æˆåŠŸ, åˆªé™¤æ•¸é‡)
        """
        try:
            deleted_count = 0

            # æŒ‰åœ–ç‰‡åˆ†çµ„åˆªé™¤é …ç›®
            delete_by_image = {}
            for item in delete_items:
                if not isinstance(item, dict):
                    logger.error(f"ç„¡æ•ˆçš„åˆªé™¤é …ç›®: {item}")
                    continue

                image_name = item.get('image_name')
                region_idx = item.get('region_idx')

                if not image_name or region_idx is None:
                    logger.error(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {item}")
                    continue

                if image_name not in delete_by_image:
                    delete_by_image[image_name] = []
                delete_by_image[image_name].append(region_idx)

            # å‚™ä»½åŸæ–‡ä»¶
            backup_file = self.annotations_file.with_suffix('.json.bak')
            shutil.copy2(self.annotations_file, backup_file)
            logger.info(f"å‚™ä»½æ¨™è¨»æ–‡ä»¶: {backup_file}")

            # åŸ·è¡Œåˆªé™¤
            for image_name, indices in delete_by_image.items():
                if image_name not in self.annotations:
                    logger.warning(f"åœ–ç‰‡ä¸å­˜åœ¨æ–¼æ¨™è¨»ä¸­: {image_name}")
                    continue

                ocr_results = self.annotations[image_name]['ocr_results']

                # æŒ‰é™åºæ’åºï¼Œé¿å…ç´¢å¼•æ··äº‚
                indices_sorted = sorted(set(indices), reverse=True)

                for idx in indices_sorted:
                    if 0 <= idx < len(ocr_results):
                        deleted_region = ocr_results.pop(idx)
                        deleted_count += 1
                        logger.info(
                            f"åˆªé™¤å€åŸŸ: {image_name}_{idx} - {deleted_region.get('text', '')}")
                    else:
                        logger.warning(f"ç„¡æ•ˆçš„ç´¢å¼•: {image_name}_{idx}")

                # å¦‚æœåœ–ç‰‡æ²’æœ‰ä»»ä½• OCR çµæœäº†ï¼Œç§»å‹•åœ–ç‰‡åˆ° deleted è³‡æ–™å¤¾
                if len(ocr_results) == 0:
                    self._move_image_to_deleted(image_name)
                    del self.annotations[image_name]
                    logger.info(f"åˆªé™¤æ•´å€‹åœ–ç‰‡æ¨™è¨»: {image_name}")

            # ä¿å­˜æ›´æ–°å¾Œçš„æ¨™è¨»
            with open(self.annotations_file, 'w', encoding='utf-8') as f:
                json.dump(self.annotations, f, ensure_ascii=False, indent=2)

            # æ›´æ–°çµ±è¨ˆ
            self.total_regions -= deleted_count

            logger.info(f"æˆåŠŸåˆªé™¤ {deleted_count} å€‹å€åŸŸ")
            return True, deleted_count

        except Exception as e:
            logger.error(f"åˆªé™¤å€åŸŸå¤±æ•—: {e}")
            # æ¢å¾©å‚™ä»½
            backup_file = self.annotations_file.with_suffix('.json.bak')
            if backup_file.exists():
                shutil.copy2(backup_file, self.annotations_file)
                logger.info("å·²å¾å‚™ä»½æ¢å¾©")
            return False, 0

    def _move_image_to_deleted(self, image_name: str) -> None:
        """
        å°‡åœ–ç‰‡ç§»å‹•åˆ° deleted è³‡æ–™å¤¾

        Args:
            image_name: åœ–ç‰‡åç¨±
        """
        try:
            if image_name not in self.annotations:
                return

            anno = self.annotations[image_name]

            # ç§»å‹•è™•ç†å¾Œçš„åœ–ç‰‡
            processed_path = Path(anno.get('processed_image_path', ''))
            if processed_path.exists():
                dest = self.deleted_dir / processed_path.name
                shutil.move(str(processed_path), str(dest))
                logger.info(f"ç§»å‹•åœ–ç‰‡åˆ° deleted: {processed_path.name}")

            # ç§»å‹•åŸå§‹åœ–ç‰‡
            original_path = Path(anno.get('original_image_path', ''))
            if original_path.exists():
                dest = self.deleted_dir / original_path.name
                shutil.move(str(original_path), str(dest))
                logger.info(f"ç§»å‹•åŸå§‹åœ–ç‰‡åˆ° deleted: {original_path.name}")

        except Exception as e:
            logger.error(f"ç§»å‹•åœ–ç‰‡å¤±æ•— {image_name}: {e}")

    def delete_image(self, image_name: str) -> bool:
        """
        åˆªé™¤æ•´å€‹åœ–ç‰‡åŠå…¶æ‰€æœ‰æ¨™è¨»

        Args:
            image_name: åœ–ç‰‡åç¨±

        Returns:
            æ˜¯å¦æˆåŠŸåˆªé™¤
        """
        try:
            if image_name not in self.annotations:
                logger.warning(f"åœ–ç‰‡ä¸å­˜åœ¨: {image_name}")
                return False

            # å‚™ä»½
            backup_file = self.annotations_file.with_suffix('.json.bak')
            shutil.copy2(self.annotations_file, backup_file)

            # ç§»å‹•åœ–ç‰‡
            self._move_image_to_deleted(image_name)

            # åˆªé™¤æ¨™è¨»
            region_count = len(
                self.annotations[image_name].get('ocr_results', []))
            del self.annotations[image_name]

            # ä¿å­˜
            with open(self.annotations_file, 'w', encoding='utf-8') as f:
                json.dump(self.annotations, f, ensure_ascii=False, indent=2)

            # æ›´æ–°çµ±è¨ˆ
            self.total_regions -= region_count

            logger.info(f"æˆåŠŸåˆªé™¤åœ–ç‰‡: {image_name} ({region_count} å€‹å€åŸŸ)")
            return True

        except Exception as e:
            logger.error(f"åˆªé™¤åœ–ç‰‡å¤±æ•— {image_name}: {e}")
            # æ¢å¾©å‚™ä»½
            backup_file = self.annotations_file.with_suffix('.json.bak')
            if backup_file.exists():
                shutil.copy2(backup_file, self.annotations_file)
                logger.info("å·²å¾å‚™ä»½æ¢å¾©")
            return False


# Flask æ‡‰ç”¨
app = Flask(__name__)
verifier: Optional[QuickVerifier] = None


@app.route('/')
def index():
    """ä¸»é é¢"""
    if verifier is None:
        abort(500, "Verifier not initialized")

    items = verifier.get_verification_data()

    # æŒ‰ä¿¡å¿ƒåº¦æ’åº (ä½ä¿¡å¿ƒåº¦å„ªå…ˆ)
    items_sorted = sorted(items, key=lambda x: x['confidence'])

    # æª¢æŸ¥ dataset_gt å’Œ dataset_lmdb æ˜¯å¦å­˜åœ¨
    dataset_exists = (Path('./dataset_gt/train/gt.txt').exists())
    lmdb_exists = (Path('./dataset_lmdb/train').exists())

    stats = {
        'total': len(items),
        'verified': sum(1 for item in items if item['verified']),
        'low_confidence': sum(1 for item in items if item['confidence'] < 0.8),
        'dataset_exists': dataset_exists,
        'lmdb_exists': lmdb_exists,
    }

    return render_template('index.html', items=items_sorted, stats=stats)


@app.route('/api/verify', methods=['POST'])
def verify():
    """ä¿å­˜é©—è­‰çµæœ"""
    if verifier is None:
        return jsonify({'success': False, 'error': 'Verifier not initialized'}), 500

    data = request.json or {}
    if not isinstance(data, dict):
        return jsonify({'success': False, 'error': 'ç„¡æ•ˆçš„è«‹æ±‚æ ¼å¼'}), 400

    updates = data.get('updates', [])

    success = verifier.save_verification(updates)

    return jsonify({'success': success})


@app.route('/api/batch_verify', methods=['POST'])
def batch_verify():
    """æ‰¹é‡é©—è­‰ (æ¨™è¨˜ç‚ºæ­£ç¢º)"""
    if verifier is None:
        return jsonify({'success': False, 'error': 'Verifier not initialized'}), 500

    try:
        data = request.json
        if not data:
            return jsonify({'success': False, 'error': 'ç„¡æ•ˆçš„è«‹æ±‚æ•¸æ“š'}), 400

        items = data.get('items', [])
        if not items:
            return jsonify({'success': False, 'error': 'æ²’æœ‰è¦é©—è­‰çš„é …ç›®'}), 400

        updates = []
        for item in items:
            if not isinstance(item, dict):
                continue
            updates.append({
                'image_name': item.get('image_name'),
                'region_idx': item.get('region_idx'),
                'verified': True
            })

        success = verifier.save_verification(updates)

        return jsonify({'success': success, 'count': len(updates)})
    except Exception as e:
        logger.error(f"æ‰¹é‡é©—è­‰å¤±æ•—: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/delete_regions', methods=['POST'])
def delete_regions():
    """åˆªé™¤é¸ä¸­çš„æ–‡å­—å€åŸŸ"""
    if verifier is None:
        return jsonify({'success': False, 'error': 'Verifier not initialized'}), 500

    try:
        data = request.json
        if not data:
            return jsonify({'success': False, 'error': 'ç„¡æ•ˆçš„è«‹æ±‚æ•¸æ“š'}), 400

        items = data.get('items', [])
        if not items:
            return jsonify({'success': False, 'error': 'æ²’æœ‰è¦åˆªé™¤çš„é …ç›®'}), 400

        # é©—è­‰è¼¸å…¥
        delete_items = []
        for item in items:
            if not isinstance(item, dict):
                continue
            image_name = item.get('image_name')
            region_idx = item.get('region_idx')
            if image_name and region_idx is not None:
                delete_items.append({
                    'image_name': image_name,
                    'region_idx': region_idx
                })

        if not delete_items:
            return jsonify({'success': False, 'error': 'æ²’æœ‰æœ‰æ•ˆçš„åˆªé™¤é …ç›®'}), 400

        success, count = verifier.delete_regions(delete_items)

        return jsonify({
            'success': success,
            'count': count,
            'message': f'æˆåŠŸåˆªé™¤ {count} å€‹å€åŸŸ'
        })
    except Exception as e:
        logger.error(f"åˆªé™¤å€åŸŸå¤±æ•—: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/delete_image', methods=['POST'])
def delete_image():
    """åˆªé™¤æ•´å€‹åœ–ç‰‡"""
    if verifier is None:
        return jsonify({'success': False, 'error': 'Verifier not initialized'}), 500

    try:
        data = request.json
        if not data:
            return jsonify({'success': False, 'error': 'ç„¡æ•ˆçš„è«‹æ±‚æ•¸æ“š'}), 400

        image_name = data.get('image_name')
        if not image_name:
            return jsonify({'success': False, 'error': 'ç¼ºå°‘åœ–ç‰‡åç¨±'}), 400

        success = verifier.delete_image(image_name)

        return jsonify({
            'success': success,
            'message': f'æˆåŠŸåˆªé™¤åœ–ç‰‡: {image_name}' if success else 'åˆªé™¤å¤±æ•—'
        })
    except Exception as e:
        logger.error(f"åˆªé™¤åœ–ç‰‡å¤±æ•—: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/upload', methods=['POST'])
def upload_image():
    """ä¸Šå‚³æ”¶æ“šåœ–ç‰‡åˆ° input/ ç›®éŒ„ä¸¦è‡ªå‹•è™•ç†"""
    if verifier is None:
        return jsonify({'success': False, 'error': 'Verifier not initialized'}), 500

    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'æ²’æœ‰ä¸Šå‚³æ–‡ä»¶'}), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({'success': False, 'error': 'æ–‡ä»¶åç‚ºç©º'}), 400

        # æª¢æŸ¥æ–‡ä»¶é¡å‹
        allowed_extensions = {'.jpg', '.jpeg', '.png'}
        file_ext = Path(file.filename).suffix.lower()
        if file_ext not in allowed_extensions:
            return jsonify({'success': False, 'error': f'ä¸æ”¯æŒçš„æ–‡ä»¶é¡å‹: {file_ext}'}), 400

        # ä¿å­˜åˆ° input/ ç›®éŒ„
        file_path = verifier.input_dir / file.filename
        file.save(str(file_path))
        logger.info(f"å·²ä¸Šå‚³æ–‡ä»¶: {file.filename}")

        # è‡ªå‹•è™•ç†
        import sys
        sys.path.insert(0, str(Path(__file__).parent))
        from create_receipt_dataset import ReceiptDatasetCreator

        creator = ReceiptDatasetCreator()
        annotation = creator.ocr_image(file_path)
        creator.annotations[file.filename] = annotation
        creator.save_annotations()

        # é‡æ–°è¼‰å…¥ verifier çš„æ¨™è¨»
        verifier.annotations = creator.annotations

        return jsonify({
            'success': True,
            'message': f'æˆåŠŸä¸Šå‚³ä¸¦è™•ç†: {file.filename}',
            'regions_found': len(annotation.get('ocr_results', []))
        })

    except Exception as e:
        logger.error(f"ä¸Šå‚³è™•ç†å¤±æ•—: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/generate_dataset', methods=['POST'])
def generate_dataset():
    """ç”Ÿæˆè¨“ç·´æ•¸æ“šé›†ï¼ˆgt.txt æ ¼å¼ï¼‰"""
    if verifier is None:
        return jsonify({'success': False, 'error': 'Verifier not initialized'}), 500

    try:
        # æª¢æŸ¥æ˜¯å¦æœ‰å·²é©—è­‰çš„æ•¸æ“šï¼ˆæª¢æŸ¥æ¯å€‹ OCR çµæœï¼‰
        verified_count = 0
        for anno in verifier.annotations.values():
            for ocr_result in anno.get('ocr_results', []):
                if ocr_result.get('verified', False):
                    verified_count += 1

        if verified_count == 0:
            return jsonify({
                'success': False,
                'error': 'æ²’æœ‰å·²é©—è­‰çš„æ•¸æ“šï¼è«‹å…ˆé©—è­‰è‡³å°‘ä¸€å€‹æ–‡å­—å€åŸŸã€‚'
            }), 400

        # èª¿ç”¨æ•¸æ“šé›†ç”Ÿæˆå™¨
        import sys
        sys.path.insert(0, str(Path(__file__).parent))
        from create_receipt_dataset import ReceiptDatasetCreator

        creator = ReceiptDatasetCreator()
        creator.annotations = verifier.annotations
        creator.generate_training_dataset()

        return jsonify({
            'success': True,
            'message': f'æˆåŠŸç”Ÿæˆè¨“ç·´æ•¸æ“šé›†ï¼å·²é©—è­‰ {verified_count} å€‹æ–‡å­—å€åŸŸã€‚',
            'verified_count': verified_count
        })

    except Exception as e:
        logger.error(f"ç”Ÿæˆæ•¸æ“šé›†å¤±æ•—: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/convert_to_lmdb', methods=['POST'])
def convert_to_lmdb():
    """è½‰æ› dataset ç‚º LMDB æ ¼å¼"""
    import subprocess
    import sys

    if verifier is None:
        return jsonify({'success': False, 'error': 'Verifier not initialized'}), 500

    try:
        dataset_dir = Path('./dataset_gt')
        lmdb_output_dir = Path('./dataset_lmdb')

        # æª¢æŸ¥ dataset_gt ç›®éŒ„æ˜¯å¦å­˜åœ¨
        if not dataset_dir.exists():
            return jsonify({
                'success': False,
                'error': 'dataset_gt ç›®éŒ„ä¸å­˜åœ¨ï¼è«‹å…ˆç”Ÿæˆè¨“ç·´æ•¸æ“šé›†ã€‚'
            }), 400

        # æª¢æŸ¥ gt.txt æª”æ¡ˆ
        train_gt = dataset_dir / 'train' / 'gt.txt'
        valid_gt = dataset_dir / 'valid' / 'gt.txt'
        test_gt = dataset_dir / 'test' / 'gt.txt'

        if not train_gt.exists():
            return jsonify({
                'success': False,
                'error': 'train/gt.txt ä¸å­˜åœ¨ï¼è«‹å…ˆç”Ÿæˆè¨“ç·´æ•¸æ“šé›†ã€‚'
            }), 400

        # å‰µå»º LMDB è¼¸å‡ºç›®éŒ„
        lmdb_output_dir.mkdir(parents=True, exist_ok=True)

        # æª¢æŸ¥ create_lmdb_dataset.py è…³æœ¬
        script_path = Path(
            './deep-text-recognition-benchmark/create_lmdb_dataset.py')
        if not script_path.exists():
            return jsonify({
                'success': False,
                'error': 'create_lmdb_dataset.py ä¸å­˜åœ¨ï¼'
            }), 400

        # è½‰æ›æ‰€æœ‰è³‡æ–™é›† (train, valid, test)
        splits_to_convert = []

        if train_gt.exists():
            splits_to_convert.append(('train', train_gt))
        if valid_gt.exists():
            splits_to_convert.append(('valid', valid_gt))
        if test_gt.exists():
            splits_to_convert.append(('test', test_gt))

        if not splits_to_convert:
            return jsonify({
                'success': False,
                'error': 'æ²’æœ‰æ‰¾åˆ°ä»»ä½• gt.txt æª”æ¡ˆï¼'
            }), 400

        all_outputs = []

        for split_name, gt_file in splits_to_convert:
            # åŸ·è¡Œè½‰æ›å‘½ä»¤
            cmd = [
                sys.executable,
                str(script_path),
                str(dataset_dir / split_name),  # inputPath
                str(gt_file),                    # gtFile
                str(lmdb_output_dir / split_name)  # outputPath
            ]

            logger.info(f"åŸ·è¡Œ LMDB è½‰æ› ({split_name}): {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é˜è¶…æ™‚
            )

            if result.returncode != 0:
                logger.error(f"LMDB è½‰æ›å¤±æ•— ({split_name}): {result.stderr}")
                return jsonify({
                    'success': False,
                    'error': f'LMDB è½‰æ›å¤±æ•— ({split_name}): {result.stderr}'
                }), 500

            logger.info(f"LMDB è½‰æ›è¼¸å‡º ({split_name}): {result.stdout}")
            all_outputs.append(f"âœ… {split_name}: {result.stdout.strip()}")

        return jsonify({
            'success': True,
            'message': f'æˆåŠŸè½‰æ› {len(splits_to_convert)} å€‹è³‡æ–™é›†ç‚º LMDB æ ¼å¼ï¼',
            'output': '\n'.join(all_outputs)
        })

    except subprocess.TimeoutExpired:
        logger.error("LMDB è½‰æ›è¶…æ™‚")
        return jsonify({'success': False, 'error': 'è½‰æ›è¶…æ™‚ï¼è«‹æª¢æŸ¥æ•¸æ“šé›†å¤§å°ã€‚'}), 500
    except Exception as e:
        logger.error(f"LMDB è½‰æ›å¤±æ•—: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/reprocess_images', methods=['POST'])
def reprocess_images():
    """é‡æ–°è™•ç† input ç›®éŒ„ä¸­çš„æ‰€æœ‰åœ–ç‰‡ï¼ˆå¼·åˆ¶é‡æ–° OCRï¼‰"""
    if verifier is None:
        return jsonify({'success': False, 'error': 'Verifier not initialized'}), 500

    try:
        # æª¢æŸ¥ input ç›®éŒ„
        image_files = list(verifier.input_dir.glob('*.jpg')) + \
            list(verifier.input_dir.glob('*.jpeg')) + \
            list(verifier.input_dir.glob('*.png'))

        if not image_files:
            return jsonify({
                'success': False,
                'error': 'input ç›®éŒ„ä¸­æ²’æœ‰åœ–ç‰‡ï¼'
            }), 400

        logger.info(f"é–‹å§‹é‡æ–°è™•ç† {len(image_files)} å¼µåœ–ç‰‡...")

        # å°å…¥ ReceiptDatasetCreator
        import sys
        sys.path.insert(0, str(Path(__file__).parent))
        from create_receipt_dataset import ReceiptDatasetCreator

        creator = ReceiptDatasetCreator()
        processed_count = 0
        failed_count = 0

        for img_path in image_files:
            try:
                logger.info(f"é‡æ–°è™•ç†: {img_path.name}")
                annotation = creator.ocr_image(img_path)
                creator.annotations[img_path.name] = annotation
                verifier.annotations[img_path.name] = annotation
                processed_count += 1
                logger.info(
                    f"âœ“ {img_path.name}: ç™¼ç¾ {len(annotation.get('ocr_results', []))} å€‹æ–‡å­—å€åŸŸ")
            except Exception as e:
                logger.error(f"è™•ç† {img_path.name} å¤±æ•—: {e}")
                failed_count += 1

        # ä¿å­˜æ›´æ–°çš„æ¨™è¨»
        creator.save_annotations()
        verifier.save_annotations()

        # æ›´æ–°çµ±è¨ˆ
        verifier.total_regions = sum(
            len(anno.get('ocr_results', []))
            for anno in verifier.annotations.values()
        )

        return jsonify({
            'success': True,
            'message': f'é‡æ–°è™•ç†å®Œæˆï¼\næˆåŠŸ: {processed_count}\nå¤±æ•—: {failed_count}',
            'processed': processed_count,
            'failed': failed_count
        })

    except Exception as e:
        logger.error(f"é‡æ–°è™•ç†å¤±æ•—: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500


def main():
    import argparse

    parser = argparse.ArgumentParser(description='å¿«é€Ÿé©—è­‰å·¥å…·')
    parser.add_argument('--processed', default='./processed', help='è™•ç†çµæœç›®éŒ„')
    parser.add_argument('--input', default='./input', help='è¼¸å…¥åœ–ç‰‡ç›®éŒ„')
    parser.add_argument('--port', type=int, default=5001, help='ä¼ºæœå™¨ç«¯å£')

    args = parser.parse_args()

    global verifier
    verifier = QuickVerifier(args.processed, args.input)

    print("\n" + "="*70)
    print("ğŸš€ é¦™æ¸¯æ”¶æ“š OCR é©—è­‰å·¥å…·å•Ÿå‹•!")
    print("="*70)
    print(f"\nğŸ“Š çµ±è¨ˆ:")
    print(f"   ç¸½æ–‡å­—å€åŸŸ: {verifier.total_regions}")
    print(f"   è¼¸å…¥ç›®éŒ„: {verifier.input_dir}")
    print(f"   è™•ç†ç›®éŒ„: {verifier.processed_dir}")
    print(f"\nğŸŒ æ‰“é–‹ç€è¦½å™¨è¨ªå•:")
    print(f"   http://localhost:{args.port}")
    print(f"\nğŸ’¡ å·¥ä½œæµç¨‹:")
    print(f"   1. ä¸Šå‚³æ”¶æ“šåœ–ç‰‡ â†’ è‡ªå‹• OCR")
    print(f"   2. äººå·¥é©—è­‰å’Œä¿®æ­£")
    print(f"   3. ç”Ÿæˆè¨“ç·´æ•¸æ“šé›†")
    print(f"\nâŒ¨ï¸  å¿«æ·éµ:")
    print(f"   Ctrl+S: ä¿å­˜æ‰€æœ‰è®Šæ›´")
    print(f"   Delete: åˆªé™¤é¸ä¸­é …")
    print("\n" + "="*70 + "\n")

    app.run(host='0.0.0.0', port=args.port, debug=True)


if __name__ == '__main__':
    main()
